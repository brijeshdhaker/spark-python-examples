#
#
#
version: '3.1'
#
services:
#
#  namenode:
#    image: hadoop:3.2.0
#    container_name: namenode
#    ports:
#      - "9000:9000"
#      - "9866:9866"  
#      - "9870:9870"
#      - "9864:9864" 
#    command: /usr/local/bin/start-hdfs.sh
#    hostname: namenode
#    volumes:
#      - /apps/hostpath/spark/data:/data
#      - /apps/hostpath/spark/in:/in
#    environment:
#      HDFS_MODE: SingleNode    
#
  hive:
    image: hive:3.1.2
    container_name: hive
    hostname: hiveserver
#    depends_on:
#      - namenode
    command: /usr/local/bin/start-hive.sh
#    restart: always
    volumes:
      - /apps/hostpath/hive:/user/hive
    environment:
      DATA_DIR: /user/hive/warehouse
    ports:
      - 10000:10000
      - 10002:10002