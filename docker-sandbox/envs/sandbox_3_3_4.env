#
#
#
CLUSTER_NAME=docker-sandbox

#
# Zookeeper Server
#
ALLOW_ANONYMOUS_LOGIN=yes

#
# Kafka
#
KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
ALLOW_PLAINTEXT_LISTENER=yes
KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:19092
KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:19092
KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
KAFKA_HEAP_OPTS=-Xmx512m -Xms512m

#
#
#
CORE_CONF_fs_defaultFS=hdfs://namenode:9000
CORE_CONF_hadoop_http_staticuser_user=root
CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec
CORE_CONF_hadoop_proxyuser_root_hosts=*
CORE_CONF_hadoop_proxyuser_root_groups=*
CORE_CONF_hadoop_proxyuser_brijeshdhaker_hosts=*
CORE_CONF_hadoop_proxyuser_brijeshdhaker_groups=*
CORE_CONF_hadoop_proxyuser_spark_hosts=*
CORE_CONF_hadoop_proxyuser_spark_groups=*
CORE_CONF_hadoop_proxyuser_zeppelin_hosts=*
CORE_CONF_hadoop_proxyuser_zeppelin_groups=*
CORE_CONF_hadoop_proxyuser_hue_hosts=*
CORE_CONF_hadoop_proxyuser_hue_groups=*
CORE_CONF_hadoop_proxyuser_hadoop_hosts=*
CORE_CONF_hadoop_proxyuser_hadoop_groups=*
CORE_CONF_hadoop_proxyuser_yarn_hosts=*
CORE_CONF_hadoop_proxyuser_yarn_groups=*
CORE_CONF_hadoop_proxyuser_mapred_hosts=*
CORE_CONF_hadoop_proxyuser_mapred_groups=*
CORE_CONF_hadoop_proxyuser_hive_hosts=*
CORE_CONF_hadoop_proxyuser_hive_groups=*
CORE_CONF_hadoop_proxyuser_hbase_hosts=*
CORE_CONF_hadoop_proxyuser_hbase_groups=*


#
#
#
HDFS_CONF_dfs_webhdfs_enabled=true
HDFS_CONF_dfs_permissions_enabled=false
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
HDFS_CONF_dfs_namenode_name_dir=file:///hadoop/dfs/name
HDFS_CONF_dfs_datanode_data_dir=file:///hadoop/dfs/data
HDFS_CONF_dfs_replication=1
#HDFS_CONF_dfs_namenode_checkpoint_dir=file:///hadoop/dfs/namesecondary

#
YARN_CONF_yarn_resourcemanager_recovery_enabled=false
YARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstate
YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=true
YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
YARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler
YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031

YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5
YARN_CONF_yarn_nodemanager_remote___app___log___dir=/tmp/logs
YARN_CONF_yarn_nodemanager_remote___app___log___dir___suffix=logs
YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle
YARN_CONF_yarn_nodemanager_resource_memory___mb=8192
YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8
YARN_CONF_yarn_nodemanager_vmem___check___enabled=false

YARN_CONF_yarn_scheduler_minimum___allocation___mb=128
YARN_CONF_yarn_scheduler_minimum___allocation___vcores=1
YARN_CONF_yarn_scheduler_maximum___allocation___mb=8192
YARN_CONF_yarn_scheduler_maximum___allocation___vcores=8
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=8

YARN_CONF_yarn_timeline___service_enabled=false
YARN_CONF_yarn_timeline___service_generic___application___history_enabled=true
YARN_CONF_yarn_timeline___service_hostname=timelineserver
YARN_CONF_yarn_timeline___service_leveldb___timeline___store_path=/hadoop/yarn/timeline
#YARN_CONF_yarn_timeline___service_leveldb___state___store_path=/hadoop/yarn/state

YARN_CONF_mapreduce_map_output_compress=true
YARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodec

YARN_CONF_yarn_log___aggregation___enable=true
YARN_CONF_yarn_log___aggregation_retain___seconds=604800
#YARN_CONF_yarn_log_server_url=http://timelineserver:8188/applicationhistory/logs/
YARN_CONF_yarn_log_server_url=http://historyserver:19888/jobhistory/logs

#
MAPRED_CONF_mapreduce_framework_name=yarn
MAPRED_CONF_yarn_app_mapreduce_am_resource_mb=1024
MAPRED_CONF_yarn_app_mapreduce_am_resource_cpu___vcores=1
MAPRED_CONF_yarn_app_mapreduce_am_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.3.4
MAPRED_CONF_mapreduce_map_memory_mb=1536
MAPRED_CONF_mapreduce_map_java_opts=-Xmx1024M
#MAPRED_CONF_mapreduce_map_cpu_vcores=1
MAPRED_CONF_mapreduce_map_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.3.4
MAPRED_CONF_mapreduce_reduce_memory_mb=3072
MAPRED_CONF_mapreduce_reduce_java_opts=-Xmx2560M
#MAPRED_CONF_mapreduce_reduce_cpu_vcores=1
MAPRED_CONF_mapreduce_reduce_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.3.4
#MAPRED_CONF_mapreduce_jobhistory_intermediate___done___dir=${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate
#MAPRED_CONF_mapreduce_jobhistory_done___dir=${yarn.app.mapreduce.am.staging-dir}/history/done
MAPRED_CONF_mapreduce_jobhistory_address=0.0.0.0:10020
MAPRED_CONF_mapreduce_jobhistory_webapp_address=historyserver:19888

#
# HBASE Server Configuration
#
HBASE_CONF_hbase_rootdir=hdfs://namenode:9000/hbase
HBASE_CONF_hbase_cluster_distributed=true
HBASE_CONF_hbase_unsafe_stream_capability_enforce=false
HBASE_CONF_hbase_tmp_dir=./tmp
HBASE_CONF_hbase_zookeeper_quorum=zookeeper
HBASE_CONF_hbase_master=hbase-master:16000
HBASE_CONF_hbase_master_hostname=hbase-master
HBASE_CONF_hbase_master_port=16000
HBASE_CONF_hbase_master_info_port=16010
#HBASE_CONF_hbase_master_info_bindAddress=hbase-master
HBASE_CONF_hbase_regionserver_port=16020
HBASE_CONF_hbase_regionserver_info_port=16030
HBASE_MANAGES_ZK=false
#HBASE_CONF_hbase_regionserver_info_bindAddress=hbase-regionserver
#HBASE_CONF_hbase_zookeeper_property_clientPort=10231
#HBASE_CONF_hbase_zookeeper_property_dataDir=/apps/sandbox/zookeeper/data/hbase-2.4.9

#
# Hive Server Configuration
#

# org.postgresql.Driver
#HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-postgresql/metastore
#HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
#HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hiveadmin
#HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hiveadmin

# com.mysql.jdbc.Driver  or com.mysql.cj.jdbc.Driver
HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:mysql://mysqlserver/metastore?createDatabaseIfNotExist=true
HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=com.mysql.cj.jdbc.Driver
HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hiveadmin
HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hiveadmin

#
HIVE_SITE_CONF_datanucleus_autoCreateSchema=false
HIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083
HIVE_SITE_CONF_hive_metastore_event_db_notification_api_auth=false
HIVE_SITE_CONF_hive_metastore_warehouse_dir=hdfs://namenode:9000/user/hive/warehouse
HIVE_SITE_CONF_hive_log_explain_output=true
HIVE_SERVER2_THRIFT_PORT=10000
#HIVE_SITE_CONF_hive_aux_jars_path=file:///opt/hbase-2.4.9/lib/hbase-zookeeper-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-mapreduce-2.4.9.jar,file:///opt/hbase-2.4.9/lib/jackson-annotations-2.10.1.jar,file:///opt/hbase-2.4.9/lib/hbase-shaded-miscellaneous-3.5.1.jar,file:///opt/hbase-2.4.9/lib/jackson-databind-2.10.1.jar,file:///opt/hbase-2.4.9/lib/hbase-hadoop-compat-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-metrics-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-client-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-protocol-shaded-2.4.9.jar,file:///opt/hbase-2.4.9/lib/jackson-core-2.10.1.jar,file:///opt/hbase-2.4.9/lib/protobuf-java-2.5.0.jar,file:///opt/hbase-2.4.9/lib/hbase-shaded-netty-3.5.1.jar,file:///opt/hbase-2.4.9/lib/metrics-core-3.2.6.jar,file:///opt/hbase-2.4.9/lib/hbase-server-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-hadoop2-compat-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-metrics-api-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-common-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-protocol-2.4.9.jar,file:///opt/hbase-2.4.9/lib/hbase-shaded-protobuf-3.5.1.jar,file:///opt/hbase-2.4.9/lib/client-facing-thirdparty/htrace-core4-4.2.0-incubating.jar

#
# Spark versions
#
SPARK_HOME=/opt/spark-3.1.2
SPARK_VERSION=3.1.2
SPARK_MASTER=spark://spark-master:7077
SPARK_MASTER_WEBUI_PORT=8080
SPARK_MASTER_LOG=/spark/logs

#
# BUG otherwise show No FileSystem for scheme: hdfs message
# HADOOP_HDFS_HOME=/opt/hadoop-3.3.4
HADOOP_VERSION=3.3.4
HADOOP_HOME=/opt/hadoop-3.3.4
HADOOP_CONF_DIR=/opt/hadoop-3.3.4/etc/hadoop
HADOOP_COMMON_HOME=/opt/hadoop-3.3.4
HADOOP_MAPRED_HOME=/opt/hadoop-3.3.4
HADOOP_YARN_HOME=/opt/hadoop-3.3.4
HADOOP_OPTS=-Djava.library.path=/opt/hadoop-3.3.4/lib/native

#
YARN_HOME=/opt/hadoop-3.3.4
YARN_CONF_DIR=/opt/hadoop-3.3.4/etc/hadoop
#
HBASE_HOME=/opt/hbase-2.4.9
#
HIVE_HOME=/opt/hive-3.1.2

#
# Zeppelin variables
#
ZEPPELIN_LOG_DIR=/apps/sandbox/zeppelin/logs
ZEPPELIN_NOTEBOOK_DIR=/opt/notebook

#
# S3 creds
#
HADOOP_AWS_VERSION=3.2.0
AWS_SDK_VERSION=1.11.655
AWS_ACCESS_KEY_ID=abc
AWS_SECRET_KEY=xyzxyzxyz
AWS_SECRET_ACCESS_KEY=xyzxyzxyz

#
# minio
#
MINIO_ACCESS_KEY=abc
MINIO_SECRET_KEY=xyzxyzxyz
S3_ENDPOINT=http://minio:9000

#
# MySql Server
#
MYSQL_OPERATIONS_USER=operate
MYSQL_OPERATIONS_PASSWORD=p@SSW0rd
MYSQL_ROOT_PASSWORD=p@SSW0rd
MYSQL_DATABASE=PUBLIC
MYSQL_USER=superuser
MYSQL_PASSWORD=p@SSW0rd
MYSQL_ROOT_HOST=172.18.0.1

#
# postgres
#
POSTGRES_USER=postgres
POSTGRES_PASSWORD=pgadmin
POSTGRES_DB=postgres
PGDATA=/var/lib/postgresql/data

#
#
#
AIRFLOW_UID=50000