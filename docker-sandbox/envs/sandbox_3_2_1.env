#
#
#
CLUSTER_NAME=docker-sandbox

#
# Zookeeper Server
#
ALLOW_ANONYMOUS_LOGIN=yes

#
# Kafka
#
KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
ALLOW_PLAINTEXT_LISTENER=yes
KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:19092
KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:19092
KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
KAFKA_HEAP_OPTS=-Xmx512m -Xms512m

#
#
#
CORE_CONF_fs_defaultFS=hdfs://namenode:9000
CORE_CONF_hadoop_http_staticuser_user=root
CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec
CORE_CONF_hadoop_proxyuser_root_hosts=*
CORE_CONF_hadoop_proxyuser_root_groups=*
CORE_CONF_hadoop_proxyuser_brijeshdhaker_hosts=*
CORE_CONF_hadoop_proxyuser_brijeshdhaker_groups=*
CORE_CONF_hadoop_proxyuser_spark_hosts=*
CORE_CONF_hadoop_proxyuser_spark_groups=*
CORE_CONF_hadoop_proxyuser_zeppelin_hosts=*
CORE_CONF_hadoop_proxyuser_zeppelin_groups=*
CORE_CONF_hadoop_proxyuser_hue_hosts=*
CORE_CONF_hadoop_proxyuser_hue_groups=*
CORE_CONF_hadoop_proxyuser_hadoop_hosts=*
CORE_CONF_hadoop_proxyuser_hadoop_groups=*
CORE_CONF_hadoop_proxyuser_yarn_hosts=*
CORE_CONF_hadoop_proxyuser_yarn_groups=*
CORE_CONF_hadoop_proxyuser_mapred_hosts=*
CORE_CONF_hadoop_proxyuser_mapred_groups=*
CORE_CONF_hadoop_proxyuser_hive_hosts=*
CORE_CONF_hadoop_proxyuser_hive_groups=*
CORE_CONF_hadoop_proxyuser_hbase_hosts=*
CORE_CONF_hadoop_proxyuser_hbase_groups=*


#
#
#
HDFS_CONF_dfs_webhdfs_enabled=true
HDFS_CONF_dfs_permissions_enabled=false
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
HDFS_CONF_dfs_namenode_name_dir=file:///hadoop/dfs/name
HDFS_CONF_dfs_datanode_data_dir=file:///hadoop/dfs/data
HDFS_CONF_dfs_replication=1
#HDFS_CONF_dfs_namenode_checkpoint_dir=file:///hadoop/dfs/namesecondary

#
YARN_CONF_yarn_resourcemanager_recovery_enabled=false
YARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstate
YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=true
YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
YARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler
YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031

YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5
YARN_CONF_yarn_nodemanager_remote___app___log___dir=/tmp/logs
YARN_CONF_yarn_nodemanager_remote___app___log___dir___suffix=logs
YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle
YARN_CONF_yarn_nodemanager_resource_memory___mb=8192
YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8
YARN_CONF_yarn_nodemanager_vmem___check___enabled=false

YARN_CONF_yarn_scheduler_minimum___allocation___mb=128
YARN_CONF_yarn_scheduler_minimum___allocation___vcores=1
YARN_CONF_yarn_scheduler_maximum___allocation___mb=8192
YARN_CONF_yarn_scheduler_maximum___allocation___vcores=8
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=8

YARN_CONF_yarn_timeline___service_enabled=false
YARN_CONF_yarn_timeline___service_generic___application___history_enabled=true
YARN_CONF_yarn_timeline___service_hostname=timelineserver
YARN_CONF_yarn_timeline___service_leveldb___timeline___store_path=/hadoop/yarn/timeline
#YARN_CONF_yarn_timeline___service_leveldb___state___store_path=/hadoop/yarn/state

YARN_CONF_mapreduce_map_output_compress=true
YARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodec

YARN_CONF_yarn_log___aggregation___enable=true
YARN_CONF_yarn_log___aggregation_retain___seconds=604800
#YARN_CONF_yarn_log_server_url=http://timelineserver:8188/applicationhistory/logs/
YARN_CONF_yarn_log_server_url=http://historyserver:19888/jobhistory/logs

#
MAPRED_CONF_mapreduce_framework_name=yarn
MAPRED_CONF_yarn_app_mapreduce_am_resource_mb=1024
MAPRED_CONF_yarn_app_mapreduce_am_resource_cpu___vcores=1
MAPRED_CONF_yarn_app_mapreduce_am_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1
MAPRED_CONF_mapreduce_map_memory_mb=1536
MAPRED_CONF_mapreduce_map_java_opts=-Xmx1024M
#MAPRED_CONF_mapreduce_map_cpu_vcores=1
MAPRED_CONF_mapreduce_map_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1
MAPRED_CONF_mapreduce_reduce_memory_mb=3072
MAPRED_CONF_mapreduce_reduce_java_opts=-Xmx2560M
#MAPRED_CONF_mapreduce_reduce_cpu_vcores=1
MAPRED_CONF_mapreduce_reduce_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1
#MAPRED_CONF_mapreduce_jobhistory_intermediate___done___dir=${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate
#MAPRED_CONF_mapreduce_jobhistory_done___dir=${yarn.app.mapreduce.am.staging-dir}/history/done
MAPRED_CONF_mapreduce_jobhistory_address=0.0.0.0:10020
MAPRED_CONF_mapreduce_jobhistory_webapp_address=historyserver:19888

#
# HBASE Server Configuration
#
HBASE_CONF_hbase_rootdir=hdfs://namenode:9000/hbase
HBASE_CONF_hbase_cluster_distributed=true
HBASE_CONF_hbase_unsafe_stream_capability_enforce=false
HBASE_CONF_hbase_tmp_dir=./tmp
HBASE_CONF_hbase_zookeeper_quorum=zookeeper
HBASE_CONF_hbase_master=hbase-master:16000
HBASE_CONF_hbase_master_hostname=hbase-master
HBASE_CONF_hbase_master_port=16000
HBASE_CONF_hbase_master_info_port=16010
#HBASE_CONF_hbase_master_info_bindAddress=hbase-master
HBASE_CONF_hbase_regionserver_port=16020
HBASE_CONF_hbase_regionserver_info_port=16030
HBASE_MANAGES_ZK=false
#HBASE_CONF_hbase_regionserver_info_bindAddress=hbase-regionserver
#HBASE_CONF_hbase_zookeeper_property_clientPort=10231
#HBASE_CONF_hbase_zookeeper_property_dataDir=/apps/sandbox/zookeeper/data/hbase-2.4.9

#
# Spark versions
#
SPARK_HOME=/opt/spark-3.1.2
SPARK_VERSION=3.1.2
SPARK_MASTER=spark://spark-master:7077
SPARK_MASTER_WEBUI_PORT=8080
SPARK_MASTER_LOG=/spark/logs

#
# BUG otherwise show No FileSystem for scheme: hdfs message
# HADOOP_HDFS_HOME=/opt/hadoop-3.2.1
HADOOP_VERSION=3.2.1
HADOOP_HOME=/opt/hadoop-3.2.1
HADOOP_CONF_DIR=/opt/hadoop-3.2.1/etc/hadoop
HADOOP_COMMON_HOME=/opt/hadoop-3.2.1
HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1
HADOOP_YARN_HOME=/opt/hadoop-3.2.1
HADOOP_OPTS=-Djava.library.path=/opt/hadoop-3.2.1/lib/native

#
YARN_HOME=/opt/hadoop-3.2.1
YARN_CONF_DIR=/opt/hadoop-3.2.1/etc/hadoop
#
HBASE_HOME=/opt/hbase-2.4.9
#
HIVE_HOME=/opt/hive-3.1.2

#
# Zeppelin variables
#
ZEPPELIN_LOG_DIR=/apps/sandbox/zeppelin/logs
ZEPPELIN_NOTEBOOK_DIR=/opt/notebook

#
# S3 creds
#
HADOOP_AWS_VERSION=3.2.0
AWS_SDK_VERSION=1.11.655
AWS_ACCESS_KEY_ID=abc
AWS_SECRET_KEY=xyzxyzxyz
AWS_SECRET_ACCESS_KEY=xyzxyzxyz

#
# minio
#
MINIO_ACCESS_KEY=abc
MINIO_SECRET_KEY=xyzxyzxyz
S3_ENDPOINT=http://minio:9000

#
# postgres
#
POSTGRES_USER=postgres
POSTGRES_PASSWORD=pgadmin
POSTGRES_DB=postgres
PGDATA=/var/lib/postgresql/data

#